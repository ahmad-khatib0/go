
+------+
| gRPC |
+------+
1- each RPC line is an endpoint in that service, The requests 
   and responses are messages that the compiler turns into Go structs,   
2- ConsumeStream—a server-side streaming RPC where the client sends a
   request to the server and gets back a stream to read a sequence of messages
3- ProduceStream—a bidirectional streaming RPC where both the client and
    server send a sequence of messages using a read-write stream. The two
    streams operate independently, so the clients and servers can read and
    write in whatever order they like. For example, the server could wait to
    receive all of the client’s requests before sending back its response. You’d
    order your calls this way if your server needed to process the requests in
    batches or aggregate a response over multiple requests. Alternatively, the
    server could send back a response for each request in lockstep. You’d
    order your calls this way if each request required its own corresponding response.

+-----+
| TLS |
+-----+
CFSSL has two tools we’ll need:
    • cfssl to sign, verify, and bundle TLS certificates and output the results as JSON. 
    • cfssljson to take that JSON output and split them into separate key, cer- tificate, CSR, and bundle files.
in ca-csr.json 
 ╒══════════════════════════════════════════════════════════════════════════════════╕
   • C—country                                                                      
   • L—locality or municipality (such as city)                                      
   • ST—state or province                                                           
   • O—organization                                                                 
   • OU—organizational unit (such as the department responsible for owning the key) 
 ╘══════════════════════════════════════════════════════════════════════════════════╛

The simplest way to implement authorization is with an access control list (ACL). An ACL is a table 
  of rules where each row says something like “Subject A is permitted to do action B on object 
  C.” For example: Alice is permitted to read Distributed Services with Go. In this example, 
  Alice is the subject, to read is the action, and Distributed Services with Go is the object.

+-----------------------------------------------------------------------------+
| The model.conf configures Casbin to use ACL as its authorization mechanism. |
+-----------------------------------------------------------------------------+

╒════════════════════════════════════════════════════════════════════════════════════════════════════════╕
  In the policy.csv file, this is an ACL table, with two entries saying that the root client has produce 
  and consume permissions on the * object (which we’re using as a wildcard,                              
  meaning any object). All other clients, including nobody, will be denied.                              
╘════════════════════════════════════════════════════════════════════════════════════════════════════════╛


╒═════════╕
│ Metrics │
╘═════════╛
Metrics measure numeric data over time, such as how many requests failed or how long each request took.
  Metrics like these help to define service-level indicators (SLI), objectives (SLO), and agreements (SLA). 
  You’ll use metrics to report the health of your system, trigger internal alerts, and graph on
  dashboards to get an idea of how your system’s doing at a glance. there are three types of metrics:

Counters
    Counters track the number of times an event happened, such as the
    number of requests that failed or the sum of some fact of your system like the number of bytes processed.
    You’ll often take a counter and use it to get a rate: the number of times an event happened in an interval
    Who cares about the total requests we’ve received other than to brag about it? What we care about is how
    many requests we’ve handled in the past second or minute—if that dropped significantly you’d want to check 
    for latency in your system. You’d want to know when your request error rate spikes so you can see
    what’s wrong and fix it.
Histograms
    Histograms show you a distribution of your data. You’ll mainly use histograms 
    for measuring the percentiles of your request duration and sizes.
Gauges
    Gauges track the current value of something. You can replace that value entirely.
    Gauges are useful for saturation-type metrics, like a host’s disk usage percentage 
    or the number of load balancers compared to your cloud provider’s limits.

┌───────────────────────────────────────────┐
  Google’s four golden signals1 to measure: 
└───────────────────────────────────────────┘
• Latency: the time it takes your service to process requests. If your latency spikes, you often need 
    to scale your system vertically by changing to an instance with more memory, CPUs, or IOPS, 
    or scale your system horizontally by adding more instances to your load balancer

• Traffic: the amount of demand on your service. For a typical web service,
    this could be requests processed per second. For an online video game or video streaming service, 
    it could be the number of concurrent users. These metrics are good for bragging rights (hopefully), 
    but more important, they can help give you an idea of the scale at which youu’re 
    working and when you’ve scaled to the point you need a new design.
    
• Errors: your service’s request failure rate. Internal server errors are par-ticularly important.

• Saturation—a measure of your service’s capacity. For example, if your
    service persists data to disk, at your current ingress rate will you run out of hard drive space soon?
    If you have an in-memory store, how much memory is your service using compared to the memory available?

• Traces comprise one or more spans. Spans can have parent/child relationships
    or be linked as siblings. Each span represents a part of the request’s execution.

OpenTelemetry8 is a Cloud Native Computing Foundation (CNCF) project that provides robust and 
    portable APIs and libraries that we can use for metrics and distributed tracing in our service. 
    (OpenCensus and OpenTracing merged to form OpenTelemetry, which is backward-compatible with existing 
    Open-Census integrations.)  OpenTelemetry’s Go gRPC integration supports traces but not metrics, 



When a test file implements TestMain(m *testing.M), Go will call TestMain(m) instead
    of running the tests directly. TestMain() gives us a place for setup that applies to all tests in that 
    file, like enabling our debug output. Flag parsing has to go in TestMain() instead of init(), 
    otherwise Go can’t define the flag and your code will error and exit


When you have an application that needs to talk to a service, the tool you
use for service discovery needs to perform the following tasks:
    • Manage a registry of services containing info such as their IPs and ports;
    • Help services find other services using the registry;
    • Health check service instances and remove them if they’re not well; and
    • Deregister services when they go offline.

Serf maintains cluster membership by using an efficient, lightweight gossip
    protocol to communicate between the service’s nodes. Unlike service registry
    projects like ZooKeeper and Consul, Serf doesn’t have a central-registry architectural style.
    Instead, each instance of your service in the cluster runs as a Serf node.
To implement service discovery with Serf we need to:
    1. Create a Serf node on each server.
    2. Configure each Serf node with an address to listen on and accept connec-tions from other Serf nodes.
    3. Configure each Serf node with addresses of other Serf nodes and join their cluster.
    4. Handle Serf’s cluster discovery events, such as when a node joins or fails in the cluster.

Serf has a lot of configurable parameters, but the five parameters you’ll typically use are:
    • NodeName—the node name acts as the node’s unique identifier across the
      Serf cluster. If you don’t set the node name, Serf uses the hostname.
      
    • BindAddr and BindPort—Serf listens on this address and port for gossiping.
    
    • Tags—Serf shares these tags to the other nodes in the cluster and should
      use these tags for simple data that informs the cluster how to handle this
      node. For example, Consul shares each node’s RPC address with Serf
      tags, and once they know each other’s RPC address, they can make RPCs
      to each other. Consul shares whether the node is a voter or non-voter, which changes the node’s
      role in the Raft cluster. In our code, similar to Consul, we’ll share each node’s user 
      configured RPC address with a Serf tag so the nodes know which addresses to send their RPCs.
      
    • EventCh—the event channel is how you’ll receive Serf’s events when a node joins or leaves the cluster.
      If you want a snapshot of the members at any point in time, you can call Serf’s Members() method.
      
    • StartJoinAddrs—when you have an existing cluster and you create a new node
      that you want to add to that cluster, you need to point your new node to
      at least one of the nodes now in the cluster. After the new node connects
      to one of those nodes in the existing cluster, it’ll learn about the rest of
      the nodes, and vice versa (the existing nodes learn about the new node).
      The StartJoinAddrs field is how you configure new nodes to join an existing
      cluster. You set the field to the addresses of nodes in the cluster, and
      Serf’s gossip protocol takes care of the rest to join your node to the cluster.
      In a production environment, specify at least three addresses to make
      your cluster resilient to one or two node failures or a disrupted network.
      


 +-----------------------------------------------------------------+
 | Consensus algorithms are tools used to get distributed services |
 | to agree on shared state even in the face of failures           |
 +-----------------------------------------------------------------+

What Is Raft and How Does It Work?
  Raft is a distributed consensus algorithm designed to be easily understood and implemented. It’s the 
  consensus algorithm behind services like Etcd—the distributed key-value store that backs Kubernetes,
  Consul, and soon Kafka whose team is migrating from ZooKeeper to Raft.
  
- A Raft cluster has one leader and the rest of the servers are followers. The leader maintains power by 
    sending heartbeat requests to its followers If the follower times out waiting for a heartbeat request 
    from the leader, then the follower becomes a candidate and begins an election to decide the next leader
    The candidate votes for itself and then requests votes from the followers
    If the candidate receives a majority of the votes, it becomes the leader, and it sends 
    heartbeat requests to the followers to establish authorit

    Followers can become candidates simultaneously if they time out at the same time waiting for the 
    leader’s heartbeats. They’ll hold their own elections and the elections might not result in a new 
    leader because of vote splitting. So they’ll hold another election. Candidates will hold elections 
    until there’s a winner that becomes the new leader.

    Every Raft server has a term: a monotonically increasing integer that tells other servers how authoritative 
    and current this server is. The servers’ terms act as a logical clock: a way to capture chronological and 
    causal relationships in distributed systems, where real-time clocks are untrustworthy and unimportant. 
    Each time a candidate begins an election, it increments its term. If the candidate wins the election 
    and becomes the leader, the followers update their terms to match and the terms don’t change until the 
    next election. Servers vote once per term for the first candidate that requests votes, as long
    as the candidate’s term is greater than the voters’. 
   ┌─────────────────────────────────────────────────────────────────────────────────────────────┐
     THESE CONDITIONS HELP PREVENT VOTE SPLITS AND ENSURE THE VOTERS ELECT AN UP-TO-DATE LEADER. 
   └─────────────────────────────────────────────────────────────────────────────────────────────┘

   LOG REPLICATOIN: 
     The leader accepts client requests, each of which represents some command to run across the cluster. 
     (In a key-value service for example, you’d have a command to assign a key’s value.) For each request, 
     the leader appends the command to its log and then requests its followers to append the command to their 
     logs. After a majority of followers have replicated the command—when the leader considers the command 
     committed the leader executes the command with a finite-state machine and responds to the client with 
     the result. The leader tracks the highest committed offset and sends this in the requests to its followers.
     When a follower receives a request, it executes all commands up to the highest committed offset with its 
     finite-state machine. All Raft servers run the same finite-state machine that defines how to handle each command

    ┌──────────────────────────────────────────────────────────────────────────────────────────────────────────┐
     The recommended number of servers in a Raft cluster is three and five. A Raft cluster of three           
     servers will tolerate a single server failure while a cluster of five will tolerate two server failures. 
    └──────────────────────────────────────────────────────────────────────────────────────────────────────────┘

  
A Raft instance comprises:
    • A finite-state machine that applies the commands you give Raft;
    • A log store where Raft stores those commands;
    • A stable store where Raft stores the cluster’s confi, servers in the cluster, their addresses, and so on;
    • A snapshot store where Raft stores compact snapshots of its data; and
    • A transport that Raft uses to connect with the server’s peers.

Your FSM must implement three methods:
    • Apply(record *raft.Log)—Raft invokes this method after committing a log entry.
    
    • Snapshot() Raft periodically calls this method to snapshot its state. For
      most services, you’ll be able to build a compacted log—for example, if we were building a 
      key-value store and we had a bunch of commands saying “set foo to bar,” “set foo to baz,” 
      “set foo to qux,” and so on, we would only set the latest command to restore the current state.
      Because we’re replicating a log itself, we need the full log to restore it.
      
    • Restore(io.ReadCloser)—Raft calls this to restore an FSM from a snapshot for instance, 
      if an EC2 instance failed and a new instance took its place.



┌────────────────────────────────────────────────┐
  Multiplex to Run Multiple Services on One Port 
└────────────────────────────────────────────────┘
Multiplexing allows you to serve different services on the same port. This makes
    your service easier to use: there’s less documentation, less configuration, and fewer connections to manage.
    And you can serve multiple services even when a firewall constrains you to one port. There’s a slight perf 
    hit on each new connection because the multiplexer reads the first bytes to identify the connection, 
    but for long-lived connections that performance hit is negligible.
    
The issue with multiplexing mutual TLS gRPC connections is that gRPC needs information 
    taken during the handshake to authenticate clients later on. So we have to multiplex before the 
    handshake and need to make a way to identify Raft from gRPC connections.
    We identify the Raft connections from the gRPC connections by making the
    Raft connections write a byte to identify them by. We write the number 1 as the first byte of our 
    Raft connections to separate them from the gRPC connec- tions. If we had other services, we could 
    differentiate them from gRPC by passing a custom dialer to the gRPC client to send the number 2 as 
    the first byte. The TLS standards4 don’t assign multiplexing schemes to the values 0–19, saying 
    that they “require coordination,” like we’ve done. It’s better to handle internal services specially 
    because you control the clients and can make them write whatever you need to identify them.



Three strategies can be used for solving the discovery and load balancing problem:
    • Server proxying—your client sends its requests to a load balancer that knows the servers 
      (either by querying a service registry or by being the service registry) and proxies the 
      requests to your back-end services.
    • External load balancing—your client queries an external load-balancing
      service that knows the servers and tells the client which server to send the RPC.
    • Client-side balancing—your client queries a service registry to learn about
      the servers, picks the server to send its RPC, and sends its RPC directly to the server.

┌────────────────────────────────────┐
  Load Balance on the Client in gRPC 
└────────────────────────────────────┘
When you call grpc.Dial, gRPC takes the address and passes it on to the resolver, and the resolver 
    discovers the servers. gRPC’s default resolver is the DNS resolver. If the address you give to gRPC has 
    multiple DNS records associated with it, gRPC will balance requests across each of those records’ servers.
    
gRPC uses round-robin load balancing by default. The round-robin algorithm works by sending the first 
    call to the first server, the second call to the second server, and so on. After the last server,
    it goes back to the first server again. So, we send each server the same number of calls. Round-robin 
    works well when each request requires the same work by the server—stateless services that defer the work 
    to a separate service like a database, for example. You can always begin with round-robin load 
    balancing and optimize later.

The issue with round-robin load balancing, however, is that it doesn’t consider
    what you know about each request, client, and server. For example:
    • If your server is a replicated distributed service with a single writer and multiple readers, 
      you’ll want to read from replicas so the writer can focus on the writes. This requires knowing 
      whether the request is a read or a write and whether the server is a primary or a replica.
    • If your service is a globally distributed service, you’ll want your clients to
      prioritize networking with local servers, which means you must know 
      the location of the clients and the servers.
    • If your system is latency sensitive, you can track metrics on how many in-flight or 
      queued requests a server has or some other combination of latency metrics and have 
      the client request the server with the smallest number.

-- Resolve the Servers
   resolver.Builder comprises two methods—Build() and Scheme():
   
    • Build() receives the data needed to build a resolver that can discover the servers (like the target address) 
      and the client connection the resolver will update with the servers it discovers. Build() sets up a client 
      connection to our server so the resolver can call the GetServers() API.

    • Scheme() returns the resolver’s scheme identifier. When you call grpc.Dial, gRPC parses out the 
      scheme from the target address you gave it and tries to find a resolver that matches, defaulting to its 
      DNS resolver. For our resolver, we'll format the target address like: proglog://your-service-address

You update the state with a slice of resolver.Address to inform the load balancer
      what servers it can choose from. A resolver.Address has three fields:
    • Addr (required)—the address of the server to connect to.
    
    • Attributes (optional but useful)—a map containing any data that’s useful for the load balancer.
      We’ll tell the picker what server is the leader and what servers are followers with this field.
      
    • ServerName (optional and you likely don’t need to set)—the name used as the transport certificate 
      authority for the address, instead of the hostname taken from the Dial target string.


-- Route and Balance Requests with Pickers
    In the gRPC architecture, pickers handle the RPC balancing logic. They’re called pickers because 
    they pick a server from the servers discovered by the resolver to handle each RPC Pickers can route 
    RPCs based on information about the RPC, client, and server, so their utility goes 
    beyond balancing to any kind of request-routing logic


┌────────────┐
  Kubernetes 
└────────────┘
- All containers running in a pod share the same network namespace, the same IP address, and the same 
     interprocess communication (IPC) namespace, and they can share the same volumes. These are logical
     hosts because a physical host (what Kubernetes calls a node) may run multiple pods.
- Controllers are control loops that watch the state of your resources and make changes where needed. 
    Kubernetes itself is made up of many controllers. For example, the Deployment controller watches your 
    Deployment resources; if you increase the replicas on a Deployment, the controller will schedule more pods.
- Try to use kubectl for one-off operations. For operations you run again and again, like deploying 
    or upgrading a service, you’ll use the Helm package manager or an operator
- Kind (an acronym for Kubernetes IN Docker) We use the Kind tool to run a local Kubernetes cluster in Docker.

- kind create cluster          #  create a Kind cluster
- kubectl cluster-info         # verify that Kind created your cluster and configured kubectl to use it

-- kind load docker-image github.com/ahmad-khatib0/go/distributed-services/proglog:0.0.1

-- Helm is the package manager for Kubernetes that enables you to distribute and install services in Kubernetes.
   Helm packages are called charts. A chart defines all resources needed to run a service in a Kubernetes cluster
-- A release is a instance of running a chart. Each time you install a chart into Kubernetes, Helm creates a release

-- helm create proglog          
-- helm template proglog                     # check out the resources Helm would create with the example chart
-- rm proglog/templates/**/*.yaml proglog/templates/NOTES.txt

StatefulSets in Kubernetes: 
-- You use StatefulSets to manage stateful applications in Kubernetes, like our service that persists 
   a log. You need a StatefulSet for any service that requires one or more of the following:

• Stable, unique network identifiers—each node in our service requires unique node names as identifiers.

• Stable, persistent storage—our service expects the data its written to persist across restarts.

• Ordered, graceful deployment and scaling—our service needs initial node
  to bootstrap the cluster and join subsequent nodes to its cluster.
  
• Ordered, automated rolling updates—we always want our cluster to have a leader, and when we roll 
  the leader we want to give the cluster enough time to elect a new leader before rolling the next node.

-- Kubernetes uses probes to know whether it needs to act on a container to improve your service’s reliability. 
   There are three types of probes:
    • Liveness probes signal that the container is alive, otherwise Kubernetes will restart the container. 
      Kubernetes calls the liveness probe throughout the container’s lifetime.

    • Readiness probes check that the container is ready to accept traffic, otherwise Kubernetes will remove the pod 
      from the service load balancers.  Kubernetes calls the readiness probe throughout the container’s lifetime.

    • Startup probes signal when the container application has started and Kubernetes can begin probing for liveness 
      and readiness. Distributed services often need to go through service discovery and join in consensus with the 
      cluster before they’re initialized. If we had a liveness probe that failed before our service finished 
      initializing, our service would continually restart. After startup, Kubernetes doesn’t call this probe again.
 
   You have three ways of running probes:
    • Making an HTTP request against a server;
    • Opening a TCP socket against a server; and
    • Running a command in the container to check it's health